# AUTOGENERATED! DO NOT EDIT! File to edit: pts/mod/_models.pct.py

__all__ = ['BoxMeta', 'BoxyardMeta', 'SyncCondition', 'SyncRecord', 'SyncStatus', 'create_boxyard_meta', 'create_user_box_group_symlinks', 'generate_unique_box_id', 'get_box_group_configs', 'get_boxyard_meta', 'get_sync_status', 'refresh_boxyard_meta']

# %% pts/mod/_models.pct.py 3
from pydantic import Field, model_validator
from pathlib import Path
import toml
from datetime import datetime, timezone
import random
from ulid import ULID
from enum import Enum
import boxyard.config
from . import const
from .config import BoxGroupConfig, BoxTimestampFormat

# %% pts/mod/_models.pct.py 5
from ._enums import BoxPart

# %% pts/mod/_models.pct.py 6
def _create_box_subid(character_set: str, length: int) -> str:
    return "".join(random.choices(character_set, k=length))

# %% pts/mod/_models.pct.py 7
def generate_unique_box_id(
    config: boxyard.config.Config,
    existing_ids: set[str],
    max_attempts: int = 100,
) -> tuple[str, str]:
    """
    Generate a box ID that doesn't collide with existing IDs.

    Args:
        config: Boxyard config (for timestamp format and subid settings)
        existing_ids: Set of existing box IDs to check against
        max_attempts: Maximum generation attempts before raising error

    Returns:
        Tuple of (creation_timestamp, box_subid)

    Raises:
        RuntimeError: If unable to generate unique ID after max_attempts
    """
    from .config import BoxTimestampFormat

    for _ in range(max_attempts):
        if config.box_timestamp_format == BoxTimestampFormat.DATE_AND_TIME:
            creation_timestamp = datetime.now(timezone.utc).strftime(
                const.BOX_TIMESTAMP_FORMAT
            )
        elif config.box_timestamp_format == BoxTimestampFormat.DATE_ONLY:
            creation_timestamp = datetime.now(timezone.utc).strftime(
                const.BOX_TIMESTAMP_FORMAT_DATE_ONLY
            )
        else:
            raise Exception(
                f"Invalid box timestamp format: {config.box_timestamp_format}"
            )

        box_subid = _create_box_subid(
            config.box_subid_character_set, config.box_subid_length
        )
        box_id = f"{creation_timestamp}_{box_subid}"

        if box_id not in existing_ids:
            return creation_timestamp, box_subid

    raise RuntimeError(
        f"Failed to generate unique box ID after {max_attempts} attempts. "
        f"This should be extremely rare - please report this issue."
    )

# %% pts/mod/_models.pct.py 8
class BoxMeta(const.StrictModel):
    creation_timestamp_utc: str
    box_subid: str
    name: str
    storage_location: str
    creator_hostname: str
    groups: list[str]
    parents: list[str] = []  # box_id values; default [] for backwards compat

    @classmethod
    def create(
        cls,
        config: boxyard.config.Config,
        name: str,
        storage_location_name: str,
        creator_hostname: str,
        groups: list[str],
        parents: list[str] | None = None,
        creation_timestamp_utc: datetime | None = None,
    ) -> "BoxMeta":
        if creation_timestamp_utc is None:
            if config.box_timestamp_format == BoxTimestampFormat.DATE_AND_TIME:
                creation_timestamp_utc = datetime.now(timezone.utc).strftime(
                    const.BOX_TIMESTAMP_FORMAT
                )
            elif config.box_timestamp_format == BoxTimestampFormat.DATE_ONLY:
                creation_timestamp_utc = datetime.now(timezone.utc).strftime(
                    const.BOX_TIMESTAMP_FORMAT_DATE_ONLY
                )
            else:
                raise Exception(
                    f"Invalid box timestamp format: {config.box_timestamp_format}"
                )
        else:
            if "_" in creation_timestamp_utc:
                creation_timestamp_utc = creation_timestamp_utc.strftime(
                    const.BOX_TIMESTAMP_FORMAT
                )
            else:
                creation_timestamp_utc = creation_timestamp_utc.strftime(
                    const.BOX_TIMESTAMP_FORMAT_DATE_ONLY
                )

        return BoxMeta(
            creation_timestamp_utc=creation_timestamp_utc,
            box_subid=_create_box_subid(
                config.box_subid_character_set, config.box_subid_length
            ),
            name=name,
            storage_location=storage_location_name,
            creator_hostname=creator_hostname,
            groups=groups,
            parents=parents or [],
        )

    @property
    def creation_timestamp_datetime(self) -> datetime:
        if "_" in self.creation_timestamp_utc:
            return datetime.strptime(
                self.creation_timestamp_utc, const.BOX_TIMESTAMP_FORMAT
            )
        else:
            return datetime.strptime(
                self.creation_timestamp_utc, const.BOX_TIMESTAMP_FORMAT_DATE_ONLY
            )

    @property
    def box_id(self) -> str:
        return f"{self.creation_timestamp_utc}_{str(self.box_subid)}"

    @property
    def index_name(self) -> str:
        return f"{self.box_id}__{self.name}"

    @classmethod
    def parse_index_name(cls, index_name: str) -> tuple[str, str]:
        """Parse index_name into (box_id, name)."""
        parts = index_name.split("__", 1)
        if len(parts) != 2:
            raise ValueError(f"Invalid index_name format: {index_name}")
        return parts[0], parts[1]

    @classmethod
    def extract_box_id(cls, index_name: str) -> str:
        """Extract just the box_id from an index_name."""
        return cls.parse_index_name(index_name)[0]

    def get_storage_location_config(
        self, config: boxyard.config.StorageConfig
    ) -> boxyard.config.StorageConfig:
        return config.storage_locations[self.storage_location]

    def get_remote_path(self, config: boxyard.config.Config) -> Path:
        return (
            config.storage_locations[self.storage_location].store_path
            / const.REMOTE_BOXES_REL_PATH
            / self.index_name
        )

    def get_local_path(self, config: boxyard.config.Config) -> Path:
        return config.local_store_path / self.storage_location / self.index_name

    def get_remote_part_path(
        self, config: boxyard.config.Config, box_part: BoxPart
    ) -> Path:
        if box_part == BoxPart.DATA:
            return self.get_remote_path(config) / const.BOX_DATA_REL_PATH
        elif box_part == BoxPart.META:
            return self.get_remote_path(config) / const.BOX_METAFILE_REL_PATH
        elif box_part == BoxPart.CONF:
            return self.get_remote_path(config) / const.BOX_CONF_REL_PATH
        else:
            raise ValueError(f"Invalid box part: {box_part}")

    def get_local_part_path(
        self, config: boxyard.config.Config, box_part: BoxPart
    ) -> Path:
        if box_part == BoxPart.DATA:
            return config.user_boxes_path / self.index_name
        elif box_part == BoxPart.META:
            return self.get_local_path(config) / const.BOX_METAFILE_REL_PATH
        elif box_part == BoxPart.CONF:
            return self.get_local_path(config) / const.BOX_CONF_REL_PATH
        else:
            raise ValueError(f"Invalid box part: {box_part}")

    def get_remote_sync_record_path(
        self, config: boxyard.config.Config, box_part: BoxPart
    ) -> Path:
        sl_conf = self.get_storage_location_config(config)
        return (
            sl_conf.store_path
            / const.SYNC_RECORDS_REL_PATH
            / self.index_name
            / f"{box_part.value}.rec"
        )

    def get_local_sync_record_path(
        self, config: boxyard.config.Config, box_part: BoxPart
    ) -> Path:
        return (
            config.boxyard_data_path
            / const.SYNC_RECORDS_REL_PATH
            / self.index_name
            / f"{box_part.value}.rec"
        )

    def check_included(self, config: boxyard.config.Config) -> bool:
        included_box_path = self.get_local_part_path(config, BoxPart.DATA)
        return included_box_path.is_dir() and included_box_path.exists()

    def save(self, config: boxyard.config.Config):
        save_path = self.get_local_part_path(config, BoxPart.META)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        model_dump = self.model_dump()
        del model_dump["creation_timestamp_utc"]
        del model_dump["box_subid"]
        del model_dump["name"]
        # Atomic write: temp file + rename
        tmp_path = save_path.with_suffix(".tmp")
        tmp_path.write_text(toml.dumps(model_dump))
        tmp_path.rename(save_path)

    @classmethod
    def load(
        cls,
        config: boxyard.config.Config,
        storage_location_name: str,
        box_index_name: str,
    ) -> "BoxMeta":
        box_id, name = box_index_name.split("__", 1)
        box_id_parts = box_id.split("_")
        if len(box_id_parts) == 3:
            creation_timestamp = f"{box_id_parts[0]}_{box_id_parts[1]}"
        elif len(box_id_parts) == 2:
            creation_timestamp = box_id_parts[0]
        else:
            raise ValueError(f"Invalid box id: {box_id}")
        box_subid = box_id_parts[-1]

        boxmeta_path = (
            config.local_store_path
            / storage_location_name
            / box_index_name
            / const.BOX_METAFILE_REL_PATH
        )
        if not boxmeta_path.exists():
            raise ValueError(f"Box meta file {boxmeta_path} does not exist.")

        return BoxMeta(
            **{
                **toml.loads(boxmeta_path.read_text()),
                "creation_timestamp_utc": creation_timestamp,
                "box_subid": box_subid,
                "name": name,
                "storage_location": storage_location_name,
            }
        )

    @classmethod
    def validate_group_name(cls, group_name: str) -> None:
        """
        Allowed characters: alphanumeric + `_`, `-`, `/`
        """
        import re

        pattern = r"^[A-Za-z0-9_\-/]+$"
        if not isinstance(group_name, str) or not re.match(pattern, group_name):
            raise ValueError(
                f"Invalid group name '{group_name}'. "
                "Allowed characters: alphanumeric, '_', '-', '/'."
            )

    @model_validator(mode="after")
    def validate_box_meta(self):
        if len(self.groups) != len(set(self.groups)):
            raise ValueError("Groups must be unique.")

        for group_name in self.groups:
            self.validate_group_name(group_name)

        if len(self.parents) != len(set(self.parents)):
            raise ValueError("Parents must be unique.")

        if self.box_id in self.parents:
            raise ValueError("A box cannot be its own parent.")

        # Test that the creation timestamp is valid
        try:
            self.creation_timestamp_datetime
        except ValueError:
            raise ValueError("Creation timestamp is not valid.")

        return self

# %% pts/mod/_models.pct.py 11
class BoxyardMeta(const.StrictModel):
    box_metas: list[BoxMeta]

    @property
    def by_storage_location(self) -> dict[str, dict[str, BoxMeta]]:
        if not hasattr(self, "__by_storage_location"):
            storage_location_names = set(rm.storage_location for rm in self.box_metas)
            self.__by_storage_location = {
                sl_name: {
                    box_meta.index_name: box_meta
                    for box_meta in self.box_metas
                    if box_meta.storage_location == sl_name
                }
                for sl_name in storage_location_names
            }
        return self.__by_storage_location

    @property
    def by_id(self) -> dict[str, BoxMeta]:
        if not hasattr(self, "__by_id"):
            self.__by_id = {
                box_meta.box_id: box_meta for box_meta in self.box_metas
            }
        return self.__by_id

    @property
    def by_box_id(self) -> dict[str, BoxMeta]:
        """Alias for by_id for clarity."""
        return self.by_id

    @property
    def by_index_name(self) -> dict[str, BoxMeta]:
        if not hasattr(self, "__by_index_name"):
            self.__by_index_name = {
                box_meta.index_name: box_meta for box_meta in self.box_metas
            }
        return self.__by_index_name

    def children_of(self, box_id: str) -> list[BoxMeta]:
        return [bm for bm in self.box_metas if box_id in bm.parents]

    def descendants_of(self, box_id: str) -> list[BoxMeta]:
        visited = set()
        queue = [box_id]
        result = []
        while queue:
            current = queue.pop(0)
            for child in self.children_of(current):
                if child.box_id not in visited:
                    visited.add(child.box_id)
                    result.append(child)
                    queue.append(child.box_id)
        return result

    def ancestors_of(self, box_id: str) -> list[BoxMeta]:
        visited = set()
        queue = [box_id]
        result = []
        while queue:
            current = queue.pop(0)
            current_meta = self.by_id.get(current)
            if current_meta is None:
                continue
            for parent_id in current_meta.parents:
                if parent_id not in visited:
                    visited.add(parent_id)
                    parent_meta = self.by_id.get(parent_id)
                    if parent_meta is not None:
                        result.append(parent_meta)
                        queue.append(parent_id)
        return result

    def roots(self) -> list[BoxMeta]:
        return [bm for bm in self.box_metas if len(bm.parents) == 0]

    def leaves(self) -> list[BoxMeta]:
        all_parent_ids = set()
        for bm in self.box_metas:
            all_parent_ids.update(bm.parents)
        return [bm for bm in self.box_metas if bm.box_id not in all_parent_ids]

    def would_create_cycle(self, child_id: str, proposed_parent_id: str) -> bool:
        if child_id == proposed_parent_id:
            return True
        ancestors = self.ancestors_of(proposed_parent_id)
        return any(a.box_id == child_id for a in ancestors)

# %% pts/mod/_models.pct.py 12
def create_boxyard_meta(config: boxyard.config.Config) -> BoxyardMeta:
    """Create a dict of all box metas. To be saved in `config.boxyard_meta_path`."""
    box_metas = []
    for storage_location_name in config.storage_locations:
        local_storage_location_path = config.local_store_path / storage_location_name
        for box_path in local_storage_location_path.glob("*"):
            if box_path.is_file():
                continue
            box_metas.append(
                BoxMeta.load(config, storage_location_name, box_path.name)
            )
    return BoxyardMeta(box_metas=box_metas)

# %% pts/mod/_models.pct.py 13
def refresh_boxyard_meta(
    config: boxyard.config.Config,
    _skip_lock: bool = False,
) -> BoxyardMeta:
    from ._utils.locking import BoxyardLockManager
    from contextlib import nullcontext

    lock_manager = BoxyardLockManager(config.boxyard_data_path)
    lock_context = nullcontext() if _skip_lock else lock_manager.global_lock()

    with lock_context:
        boxyard_meta = create_boxyard_meta(config)
        # Atomic write: temp file + rename
        tmp_path = config.boxyard_meta_path.with_suffix(".tmp")
        tmp_path.write_text(boxyard_meta.model_dump_json())
        tmp_path.rename(config.boxyard_meta_path)
    return boxyard_meta

# %% pts/mod/_models.pct.py 14
def get_boxyard_meta(
    config: boxyard.config.Config,
    force_create: bool = False,
) -> BoxyardMeta:
    if not config.boxyard_meta_path.exists() or force_create:
        refresh_boxyard_meta(config)
    return BoxyardMeta.model_validate_json(config.boxyard_meta_path.read_text())

# %% pts/mod/_models.pct.py 15
def get_box_group_configs(
    config: boxyard.config.Config,
    box_metas: list[BoxMeta],
) -> dict[str, BoxGroupConfig]:
    box_group_configs = config.box_groups.copy()
    for box_meta in box_metas:
        for group_name in box_meta.groups:
            if group_name not in box_group_configs:
                box_group_configs[group_name] = BoxGroupConfig()
    return box_group_configs, config.virtual_box_groups

# %% pts/mod/_models.pct.py 16
def create_user_box_group_symlinks(
    config: boxyard.config.Config,
):
    from collections import defaultdict
    from .config import BoxGroupTitleMode, VirtualBoxGroupConfig

    box_metas = [
        box_meta
        for box_meta in get_boxyard_meta(config).box_metas
        if box_meta.check_included(config)
    ]
    box_metas.sort(key=lambda x: x.creation_timestamp_datetime)
    groups, virtual_box_groups = get_box_group_configs(config, box_metas)
    symlink_paths = []

    for vg in virtual_box_groups:
        if vg in groups:
            print(f"Warning: Virtual box group '{vg}' is also a regular box group.")
    groups.update(virtual_box_groups)

    def _get_symlink_title(box_meta: BoxMeta, group_config: BoxGroupConfig) -> str:
        if group_config.box_title_mode == BoxGroupTitleMode.INDEX_NAME:
            title = box_meta.index_name
        elif group_config.box_title_mode == BoxGroupTitleMode.DATETIME_AND_NAME:
            title = f"{box_meta.creation_timestamp_utc}__{box_meta.name}"
        elif group_config.box_title_mode == BoxGroupTitleMode.NAME:
            title = box_meta.name
        else:
            raise Exception(f"Invalid box title mode: {group_config.box_title_mode}")
        return title

    # Generate all symlink paths to create
    _symlinks = []
    for group_name, group_config in groups.items():
        title_counter = defaultdict(int)
        group_symlink_name = group_config.symlink_name or group_name
        for box_meta in box_metas:
            if not box_meta.check_included(config):
                continue
            if isinstance(group_config, VirtualBoxGroupConfig):
                if not group_config.is_in_group(box_meta.groups):
                    continue
            else:
                if group_name not in box_meta.groups:
                    continue
            dest_path = box_meta.get_local_part_path(config, BoxPart.DATA)
            title = _get_symlink_title(box_meta, group_config)
            if title_counter[title] > 1:
                title = f"{title} (CONFLICT {title_counter[title]})"  # TODO this will break if the title contains a `(CONFLICT ...`
            title_counter[title] += 1
            symlink_path = config.user_box_groups_path / group_symlink_name / title
            _symlinks.append((dest_path, symlink_path))

    # Remove all existing symlinks that are not in the _symlinks list
    _symlink_paths = [symlink_path for _, symlink_path in _symlinks]
    for path in config.user_box_groups_path.glob("**/*"):
        if path in _symlink_paths:
            continue
        if path.is_symlink():
            path.unlink()

    # Now check for any remaining debris
    def _inspect_folder(path: Path) -> None:
        if path.is_symlink():
            return
        for p in path.iterdir():
            if p.is_dir():
                _inspect_folder(p)
            else:
                if p not in _symlink_paths:
                    raise Exception(
                        f"File '{p}' is in the user box group path '{config.user_box_groups_path}'."
                    )

    for path in config.user_box_groups_path.glob("*"):
        if path.is_dir():
            _inspect_folder(path)
        else:
            raise Exception(
                f"'{path}' is in the user box group path '{config.user_box_groups_path}' but is not a directory!"
            )

    # Create the symlinks
    for dest_path, symlink_path in _symlinks:
        symlink_path.parent.mkdir(parents=True, exist_ok=True)
        if (
            symlink_path.exists() or symlink_path.is_symlink()
        ):  # is_symlink() catches broken symlinks
            if symlink_path.is_symlink():
                if symlink_path.resolve() != dest_path.resolve():
                    symlink_path.unlink()
                else:
                    continue  # The symlink already points to the correct destination so leave it as it is
            else:
                raise Exception(
                    f"'{symlink_path}' is in the user box group path '{config.user_box_groups_path}' but is not a symlink!"
                )
        symlink_path.symlink_to(dest_path, target_is_directory=True)

    # Remove all empty group folders that are not existing groups
    def _remove_empty_non_group_folders(path: Path) -> None:
        if path.is_symlink():
            return
        for p in path.iterdir():
            if p.is_dir():
                _remove_empty_non_group_folders(p)
        is_group_folder = (
            path.relative_to(config.user_box_groups_path).as_posix() in groups
        )
        if not is_group_folder and len(list(path.iterdir())) == 0:
            path.rmdir()

    for path in config.user_box_groups_path.glob("*"):
        _remove_empty_non_group_folders(path)

# %% pts/mod/_models.pct.py 18
class SyncRecord(const.StrictModel):
    ulid: ULID = Field(default_factory=ULID)
    timestamp: datetime | None = (
        None  # Is set after validation. It's just to read it easier in printouts.
    )
    sync_complete: bool
    syncer_hostname: str

    @classmethod
    def create(cls, sync_complete: bool, syncer_hostname: str | None = None) -> None:
        from ._utils import get_hostname

        return SyncRecord(
            sync_complete=sync_complete,
            syncer_hostname=syncer_hostname or get_hostname(),
        )

    async def rclone_save(
        self, rclone_config_path: str, dest: str, dest_path: str
    ) -> None:
        from ._utils import rclone_copyto
        import tempfile

        temp_path = Path(tempfile.mkstemp(suffix=".json")[1])
        temp_path.write_text(self.model_dump_json())
        await rclone_copyto(
            rclone_config_path=rclone_config_path,
            source="",
            source_path=temp_path.as_posix(),
            dest=dest,
            dest_path=dest_path,
            dry_run=False,
        )

    @classmethod
    async def rclone_read(
        cls, rclone_config_path: str, source: str, sync_record_path: str
    ) -> str:
        from ._utils import rclone_cat

        sync_record_exists, sync_record = await rclone_cat(
            rclone_config_path=rclone_config_path,
            source=source,
            source_path=sync_record_path,
        )

        if sync_record_exists:
            return SyncRecord.model_validate_json(sync_record)
        else:
            return None

    @model_validator(mode="after")
    def validate_timestamp(self):
        if self.timestamp is None:
            self.timestamp = self.ulid.datetime
        if self.timestamp != self.ulid.datetime:
            raise ValueError("`timestamp` should be set to the ULID's datetime.")
        return self

# %% pts/mod/_models.pct.py 19
from typing import NamedTuple


class SyncCondition(Enum):
    SYNCED = "synced"
    SYNC_TO_REMOTE_INCOMPLETE = "sync_to_remote_incomplete"  # Push was interrupted, remote is corrupted
    SYNC_FROM_REMOTE_INCOMPLETE = "sync_from_remote_incomplete"  # Pull was interrupted, local is corrupted
    CONFLICT = "conflict"
    NEEDS_PUSH = "needs_push"
    NEEDS_PULL = "needs_pull"
    EXCLUDED = "excluded"
    ERROR = "error"
    TOMBSTONED = "tombstoned"  # Box was deleted on remote


class SyncStatus(NamedTuple):
    sync_condition: SyncCondition
    local_path_exists: bool
    remote_path_exists: bool
    local_sync_record: SyncRecord
    remote_sync_record: SyncRecord
    is_dir: bool
    error_message: str | None = None

# %% pts/mod/_models.pct.py 20
async def get_sync_status(
    rclone_config_path: str,
    local_path: str,
    local_sync_record_path: str,
    remote: str,
    remote_path: str,
    remote_sync_record_path: str,
) -> SyncStatus:
    from ._utils import check_last_time_modified
    from ._utils import rclone_path_exists

    local_path_exists, local_path_is_dir = await rclone_path_exists(
        rclone_config_path=rclone_config_path,
        source="",
        source_path=local_path,
    )
    local_path_is_empty = (
        True  # Default: treat as empty if doesn't exist or isn't a dir
    )
    if local_path_is_dir and local_path_exists:
        local_path_is_empty = len(list(local_path.iterdir())) == 0

    remote_path_exists, remote_path_is_dir = await rclone_path_exists(
        rclone_config_path=rclone_config_path,
        source=remote,
        source_path=remote_path,
    )

    if (local_path_exists and remote_path_exists) and (
        local_path_is_dir != remote_path_is_dir
    ):
        _local = "directory" if local_path_is_dir else "file"
        _remote = "directory" if remote_path_is_dir else "file"
        raise Exception(
            f"Local and remote paths are not both files or both directories. Local is {_local} and remote is {_remote}. Local path: '{local_path}', remote path: '{remote_path}'."
        )

    is_dir = local_path_is_dir or remote_path_is_dir

    local_sync_record = await SyncRecord.rclone_read(
        rclone_config_path=rclone_config_path,
        source="",
        sync_record_path=local_sync_record_path,
    )

    remote_sync_record = await SyncRecord.rclone_read(
        rclone_config_path=rclone_config_path,
        source=remote,
        sync_record_path=remote_sync_record_path,
    )

    local_sync_incomplete = (
        local_sync_record is not None and not local_sync_record.sync_complete
    )
    remote_sync_incomplete = (
        remote_sync_record is not None and not remote_sync_record.sync_complete
    )

    sync_records_match = (
        local_sync_record is not None and remote_sync_record is not None
    ) and (local_sync_record.ulid == remote_sync_record.ulid)

    sync_status = dict(
        local_path_exists=local_path_exists,
        remote_path_exists=remote_path_exists,
        local_sync_record=local_sync_record,
        remote_sync_record=remote_sync_record,
        is_dir=is_dir,
    )

    if remote_path_exists and remote_sync_record is None:
        sync_status["sync_condition"] = SyncCondition.ERROR
        sync_status["error_message"] = (
            f"Something wrong here. Remote path exists, but remote sync record does not exist. Local path: '{local_path}', remote path: '{remote_path}."
        )
        return SyncStatus(**sync_status)

    local_last_modified = check_last_time_modified(local_path)
    if local_last_modified is None and local_path_exists:
        if (not local_path_is_dir) or (local_path_is_dir and not local_path_is_empty):
            # Logic here: If the local path is a file, it should be able to be checked for last modification.
            # If the local path is a non-empty directory, it should also be able to be checked for last modification.
            sync_status["sync_condition"] = SyncCondition.ERROR
            sync_status["error_message"] = (
                f"Something wrong here. Local path exists and is not empty, but cannot be checked for last modification. Local path: '{local_path}', remote path: '{remote_path}."
            )
            return SyncStatus(**sync_status)

    if local_sync_incomplete and remote_sync_incomplete:
        if local_sync_record.ulid == remote_sync_record.ulid:
            # Same sync session - both sides marked by same operation
            # This is an interrupted PUSH from THIS machine (PUSH saves incomplete to both sides)
            sync_condition = SyncCondition.SYNC_TO_REMOTE_INCOMPLETE
        else:
            # Different ULIDs - inconsistent state, shouldn't happen in normal operation
            sync_status["error_message"] = (
                f"Inconsistent incomplete records (different ULIDs). "
                f"Local ULID: {local_sync_record.ulid}, Remote ULID: {remote_sync_record.ulid}"
            )
            sync_status["sync_condition"] = SyncCondition.ERROR
            return SyncStatus(**sync_status)
    elif remote_sync_incomplete:
        # Only remote is incomplete - push was interrupted (possibly from another machine)
        sync_condition = SyncCondition.SYNC_TO_REMOTE_INCOMPLETE
    elif local_sync_incomplete:
        # Only local is incomplete - pull was interrupted from THIS machine
        sync_condition = SyncCondition.SYNC_FROM_REMOTE_INCOMPLETE
    else:
        if sync_records_match:
            if (
                local_last_modified is not None
                and local_last_modified > local_sync_record.timestamp
            ):
                sync_condition = SyncCondition.NEEDS_PUSH
            else:
                sync_condition = SyncCondition.SYNCED
        else:
            if local_path_exists:
                if remote_path_exists:
                    if local_sync_record is None:
                        sync_status["sync_condition"] = SyncCondition.ERROR
                        sync_status["error_message"] = (
                            f"Something wrong here. Local sync record does not exist, but the local and remote path exists. Local path: '{local_path}', remote path: '{remote_path}."
                        )
                        return SyncStatus(**sync_status)
                    remote_sync_more_recent = (
                        remote_sync_record.ulid.datetime
                        > local_sync_record.ulid.datetime
                    )
                    if remote_sync_more_recent:
                        if (
                            local_last_modified is not None
                            and local_last_modified > local_sync_record.timestamp
                        ):
                            sync_condition = SyncCondition.CONFLICT
                        else:
                            sync_condition = SyncCondition.NEEDS_PULL
                    else:
                        sync_condition = SyncCondition.CONFLICT
                else:
                    if local_sync_record is not None:
                        sync_status["sync_condition"] = SyncCondition.ERROR
                        sync_status["error_message"] = (
                            f"Something wrong here. Local sync record exists, but remote path does not exist. Local path: '{local_path}', remote path: '{remote_path}."
                        )
                        return SyncStatus(**sync_status)
                    sync_condition = SyncCondition.NEEDS_PUSH
            else:
                if remote_path_exists:
                    sync_condition = SyncCondition.EXCLUDED
                else:
                    sync_condition = SyncCondition.SYNCED  # Synced by default, since neither local nor remote path exists. This will often be the case for `conf`, for example.

    sync_status["sync_condition"] = sync_condition
    return SyncStatus(**sync_status)
