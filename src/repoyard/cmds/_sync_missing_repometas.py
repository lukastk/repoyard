# AUTOGENERATED! DO NOT EDIT!

from pathlib import Path

from ..config import get_config, StorageType
from .._utils.sync_helper import (
    SyncFailed,
    SyncUnsafe,
    InvalidRemotePath,
    SyncStatus,
    SyncSetting,
    SyncDirection,
)
from .._utils import (
    check_interrupted,
    enable_soft_interruption,
    SoftInterruption,
)
from .. import const


async def sync_missing_repometas(
    config_path: Path,
    max_concurrent_rclone_ops: int | None = None,
    repo_index_names: list[str] | None = None,
    storage_locations: list[str] | None = None,
    sync_setting: SyncSetting = SyncSetting.CAREFUL,
    sync_direction: SyncDirection | None = None,
    verbose: bool = False,
    soft_interruption_enabled: bool = True,
) -> tuple[
    list[str],
    list[tuple[bool, SyncFailed | SyncUnsafe | InvalidRemotePath | None, SyncStatus, bool]],
]:
    """ """
    config = get_config(config_path)

    if repo_index_names is not None and storage_locations is not None:
        raise ValueError("Cannot provide both `repo_index_names` and `storage_locations`.")

    if max_concurrent_rclone_ops is None:
        max_concurrent_rclone_ops = config.max_concurrent_rclone_ops

    if soft_interruption_enabled:
        enable_soft_interruption()
    if check_interrupted():
        raise SoftInterruption()

    from repoyard._utils import rclone_lsjson, rclone_sync, async_throttler
    from repoyard._models import RepoMeta, SyncRecord, RepoPart

    for sl_name, sl_config in config.storage_locations.items():
        if sl_config.storage_type == StorageType.LOCAL:
            continue

        if storage_locations is not None and sl_name not in storage_locations:
            continue

        # Get remote repometas
        _ls_remote = await rclone_lsjson(
            config.rclone_config_path,
            source=sl_name,
            source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,
            files_only=True,
            recursive=True,
            filter=[f"+ {const.REPO_METAFILE_REL_PATH}"],
            max_depth=2,
        )
        _ls_remote = {f["Path"] for f in _ls_remote} if _ls_remote else set()

        _ls_local = await rclone_lsjson(
            config.rclone_config_path,
            source="",
            source_path=config.local_store_path / sl_name,
            files_only=True,
            recursive=True,
            filter=[f"+ /{const.REPO_METAFILE_REL_PATH}"],
            max_depth=2,
        )
        _ls_local = {f["Path"] for f in _ls_local} if _ls_local else set()

        missing_metas = sorted(_ls_remote - _ls_local)

        if repo_index_names is not None:
            missing_metas = [
                missing_meta for missing_meta in missing_metas if Path(missing_meta).parts[0] in repo_index_names
            ]

        if check_interrupted():
            raise SoftInterruption()

        missing_repo_index_names = [Path(p).parts[0] for p in missing_metas]

        if len(missing_metas) > 0:
            if verbose:
                print(f"Syncing {len(missing_metas)} missing repometas from '{sl_name}'.")
                for missing_meta in missing_metas:
                    print(f"  - {missing_meta}")

            await rclone_sync(
                rclone_config_path=config.rclone_config_path,
                source=sl_name,
                source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,
                dest="",
                dest_path=config.local_store_path / sl_name,
                filter=[f"+ /{p}" for p in missing_metas] + ["- **"],
                exclude=[],
            )

            # Create sync records
            async def _task(repo_index_name):
                repo_meta = RepoMeta.load(config, sl_name, repo_index_name)  # Used to get the paths consistently
                rec = await SyncRecord.rclone_read(
                    config.rclone_config_path,
                    sl_name,
                    repo_meta.get_remote_sync_record_path(config, RepoPart.META),
                )
                await rec.rclone_save(
                    config.rclone_config_path,
                    "",
                    repo_meta.get_local_sync_record_path(config, RepoPart.META),
                )

            await async_throttler(
                [_task(repo_index_name) for repo_index_name in missing_repo_index_names],
                max_concurrency=max_concurrent_rclone_ops,
            )
        else:
            if verbose:
                print(f"No missing repometas in '{sl_name}' to sync.")
    from repoyard._models import refresh_repoyard_meta

    refresh_repoyard_meta(config)
    return missing_metas
