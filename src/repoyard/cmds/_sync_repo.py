# AUTOGENERATED! DO NOT EDIT!

from pathlib import Path
import asyncio

from .._utils.sync_helper import sync_helper, SyncSetting, SyncDirection
from .._models import SyncStatus, RepoPart, RepoMeta, SyncCondition
from ..config import get_config, StorageType
from .._utils import (
    check_interrupted,
    enable_soft_interruption,
    SoftInterruption,
)
from .._utils.locking import RepoyardLockManager, LockAcquisitionError, REPO_SYNC_LOCK_TIMEOUT, acquire_lock_async
from .. import const
from .._tombstones import is_tombstoned, get_tombstone
from .._remote_index import find_remote_repo_by_id, update_remote_index_cache


async def sync_repo(
    config_path: Path,
    repo_index_name: str,
    sync_direction: SyncDirection | None = None,
    sync_setting: SyncSetting = SyncSetting.CAREFUL,
    sync_choices: list[RepoPart] | None = None,
    verbose: bool = False,
    show_rclone_progress: bool = False,
    soft_interruption_enabled: bool = True,
    _skip_lock: bool = False,
) -> dict[RepoPart, tuple[SyncStatus, bool]]:
    """
    Syncs a repo with its remote.

    Args:
        config_path: Path to the repoyard config file.
        repo_index_name: Full name of the repository to sync.
        sync_direction: Direction of sync.
        sync_setting: SyncSetting option (SAFE, CAREFUL, FORCE).
        sync_choices: List of RepoPart specifying what to sync. If None, all parts are synced.
        force: Force syncing, possibly overwriting changes.
        verbose: Print verbose output during sync.
        show_rclone_progress: Show rclone progress during sync.
    """
    config = get_config(config_path)
    if sync_choices is None:
        sync_choices = [repo_part for repo_part in RepoPart]

    if soft_interruption_enabled:
        enable_soft_interruption()
    from repoyard._models import get_repoyard_meta

    repoyard_meta = get_repoyard_meta(config)

    if repo_index_name not in repoyard_meta.by_index_name:
        raise ValueError(f"Repo '{repo_index_name}' not found.")

    repo_meta = repoyard_meta.by_index_name[repo_index_name]
    if repo_meta.get_storage_location_config(config).storage_type == StorageType.LOCAL:
        pass
        return
    repo_id = RepoMeta.extract_repo_id(repo_index_name)
    storage_location = repo_meta.storage_location

    _is_tombstoned = await is_tombstoned(config, storage_location, repo_id)
    if _is_tombstoned:
        _tombstone = await get_tombstone(config, storage_location, repo_id)
        _tombstone_msg = f"Repo '{repo_index_name}' was deleted"
        if _tombstone:
            _tombstone_msg += f" by {_tombstone.deleted_by_hostname} at {_tombstone.deleted_at_utc}"
        print(f"Warning: {_tombstone_msg}. Skipping sync.")
        from repoyard._models import SyncRecord

        _dummy_sync_record = SyncRecord.create(sync_complete=False)
        sync_results = {
            part: (
                SyncStatus(
                    sync_condition=SyncCondition.TOMBSTONED,
                    local_path_exists=False,
                    remote_path_exists=False,
                    local_sync_record=_dummy_sync_record,
                    remote_sync_record=_dummy_sync_record,
                    is_dir=True,
                    error_message=_tombstone_msg,
                ),
                False,
            )
            for part in sync_choices
        }
        return sync_results
    remote_index_name = await find_remote_repo_by_id(config, storage_location, repo_id)

    # If remote doesn't exist, this is a new repo - use local index_name for remote
    # If remote exists with different name, use that name for remote paths
    if remote_index_name is None:
        remote_index_name = repo_index_name

    # Precompute remote paths using the remote_index_name (which may differ from local)
    def _get_remote_path_for_index(idx_name: str) -> Path:
        return config.storage_locations[storage_location].store_path / const.REMOTE_REPOS_REL_PATH / idx_name

    def _get_remote_part_path_for_index(idx_name: str, part: RepoPart) -> Path:
        base = _get_remote_path_for_index(idx_name)
        if part == RepoPart.DATA:
            return base / const.REPO_DATA_REL_PATH
        elif part == RepoPart.META:
            return base / const.REPO_METAFILE_REL_PATH
        elif part == RepoPart.CONF:
            return base / const.REPO_CONF_REL_PATH
        raise ValueError(f"Invalid repo part: {part}")

    def _get_remote_sync_record_path_for_index(idx_name: str, part: RepoPart) -> Path:
        sl_conf = config.storage_locations[storage_location]
        return sl_conf.store_path / const.SYNC_RECORDS_REL_PATH / idx_name / f"{part.value}.rec"

    _sync_lock = None
    if not _skip_lock:
        _lock_manager = RepoyardLockManager(config.repoyard_data_path)
        _lock_path = _lock_manager.repo_sync_lock_path(repo_index_name)
        _lock_manager._ensure_lock_dir(_lock_path)
        _sync_lock = __import__("filelock").FileLock(_lock_path, timeout=0)
        await acquire_lock_async(
            _sync_lock,
            f"repo sync ({repo_index_name})",
            _lock_path,
            REPO_SYNC_LOCK_TIMEOUT,
        )

    try:
        # Prints
        if verbose:
            print(f"Syncing repo {repo_index_name} at {repo_meta.storage_location}.")

        # Get the backup locations
        sl_config = repo_meta.get_storage_location_config(config)
        local_sync_backups_path = config.local_sync_backups_path
        remote_sync_backups_path = sl_config.store_path / const.REMOTE_BACKUP_REL_PATH

        # Sync the repometa
        sync_results = {}

        if check_interrupted():
            raise SoftInterruption()

        sync_part = RepoPart.META
        if sync_part in sync_choices:
            if verbose:
                print(f"Syncing {sync_part.value}.")
            sync_results[RepoPart.META] = await sync_helper(
                rclone_config_path=config.rclone_config_path,
                sync_direction=sync_direction,
                sync_setting=sync_setting,
                local_path=repo_meta.get_local_part_path(config, RepoPart.META),
                local_sync_record_path=repo_meta.get_local_sync_record_path(config, sync_part),
                remote=repo_meta.storage_location,
                remote_path=_get_remote_part_path_for_index(remote_index_name, RepoPart.META),
                remote_sync_record_path=_get_remote_sync_record_path_for_index(remote_index_name, sync_part),
                local_sync_backups_path=local_sync_backups_path,
                remote_sync_backups_path=remote_sync_backups_path,
                verbose=verbose,
                show_rclone_progress=show_rclone_progress,
            )

        # Sync the repoconf
        if check_interrupted():
            raise SoftInterruption()

        sync_part = RepoPart.CONF
        if sync_part in sync_choices:
            if verbose:
                print("Syncing", sync_part.value)
            sync_results[sync_part] = await sync_helper(
                rclone_config_path=config.rclone_config_path,
                sync_direction=sync_direction,
                sync_setting=sync_setting,
                local_path=repo_meta.get_local_part_path(config, RepoPart.CONF),
                local_sync_record_path=repo_meta.get_local_sync_record_path(config, sync_part),
                remote=repo_meta.storage_location,
                remote_path=_get_remote_part_path_for_index(remote_index_name, RepoPart.CONF),
                remote_sync_record_path=_get_remote_sync_record_path_for_index(remote_index_name, sync_part),
                local_sync_backups_path=local_sync_backups_path,
                remote_sync_backups_path=remote_sync_backups_path,
                verbose=verbose,
                show_rclone_progress=show_rclone_progress,
                allow_missing_source=True,  # CONF is optional - may not exist on either side
            )

        # Get the now locally synced conf files for the sync of the repo data
        _rclone_include_path = repo_meta.get_local_part_path(config, RepoPart.CONF) / ".rclone_include"
        _rclone_exclude_path = repo_meta.get_local_part_path(config, RepoPart.CONF) / ".rclone_exclude"
        _rclone_filters_path = repo_meta.get_local_part_path(config, RepoPart.CONF) / ".rclone_filters"

        _rclone_include_path = _rclone_include_path if _rclone_include_path.exists() else None
        _rclone_exclude_path = (
            _rclone_exclude_path if _rclone_exclude_path.exists() else config.default_rclone_exclude_path
        )
        _rclone_filters_path = _rclone_filters_path if _rclone_filters_path.exists() else None

        # Sync the repo data
        if check_interrupted():
            raise SoftInterruption()

        sync_part = RepoPart.DATA
        if sync_part in sync_choices:
            if verbose:
                print("Syncing", sync_part.value)
            sync_results[sync_part] = await sync_helper(
                rclone_config_path=config.rclone_config_path,
                sync_direction=sync_direction,
                sync_setting=sync_setting,
                local_path=repo_meta.get_local_part_path(config, RepoPart.DATA),
                local_sync_record_path=repo_meta.get_local_sync_record_path(config, sync_part),
                remote=repo_meta.storage_location,
                remote_path=_get_remote_part_path_for_index(remote_index_name, RepoPart.DATA),
                remote_sync_record_path=_get_remote_sync_record_path_for_index(remote_index_name, sync_part),
                local_sync_backups_path=local_sync_backups_path,
                remote_sync_backups_path=remote_sync_backups_path,
                include_path=_rclone_include_path,
                exclude_path=_rclone_exclude_path,
                filters_path=_rclone_filters_path,
                verbose=verbose,
                show_rclone_progress=show_rclone_progress,
            )

        # Update remote index cache
        update_remote_index_cache(config, storage_location, repo_id, remote_index_name)

        # Refresh the repoyard meta file
        if RepoPart.META in sync_choices:
            from repoyard._models import refresh_repoyard_meta

            refresh_repoyard_meta(config)
    finally:
        if _sync_lock is not None:
            _sync_lock.release()
    return sync_results
