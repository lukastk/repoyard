{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "245c0f01",
            "metadata": {},
            "source": [
                "# _sync_repometas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d606b70",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|default_exp cmds._sync_repometas\n",
                "#|export_as_func true"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bfaacde3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Environment variable DISABLE_NBLITE_EXPORT is set to True, skipping export.\n"
                    ]
                }
            ],
            "source": [
                "#|hide\n",
                "import nblite; from nblite import show_doc; nblite.nbl_export()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6943373e",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|top_export\n",
                "from pathlib import Path\n",
                "\n",
                "from repoyard.config import get_config, StorageType\n",
                "from repoyard._utils.sync_helper import SyncFailed, SyncUnsafe, InvalidRemotePath, SyncStatus, SyncSetting, SyncDirection\n",
                "from repoyard._utils import check_interrupted, enable_soft_interruption, SoftInterruption\n",
                "from repoyard import const"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5dff643",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|set_func_signature\n",
                "async def sync_repometas(\n",
                "    config_path: Path,\n",
                "    max_concurrent_rclone_ops: int|None = None,\n",
                "    repo_full_names: list[str]|None = None,\n",
                "    storage_locations: list[str]|None = None,\n",
                "    sync_setting: SyncSetting = SyncSetting.CAREFUL,\n",
                "    sync_direction: SyncDirection|None = None,\n",
                "    verbose: bool = False,\n",
                "    soft_interruption_enabled: bool = True,\n",
                ") -> tuple[list[str], list[tuple[bool, SyncFailed|SyncUnsafe|InvalidRemotePath|None, SyncStatus, bool]]]:\n",
                "    \"\"\"\n",
                "    \"\"\"\n",
                "    ..."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "442d6588",
            "metadata": {},
            "source": [
                "Set up testing args"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d11098a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up test environment\n",
                "import tempfile\n",
                "tests_working_dir = const.pkg_path.parent / \"tmp_tests\"\n",
                "test_folder_path = Path(tempfile.mkdtemp(prefix=\"sync_repometas\", dir=\"/tmp\"))\n",
                "test_folder_path.mkdir(parents=True, exist_ok=True)\n",
                "symlink_path = tests_working_dir / \"_cmds\" / \"sync_repometas\"\n",
                "symlink_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "if symlink_path.exists() or symlink_path.is_symlink():\n",
                "    symlink_path.unlink()\n",
                "symlink_path.symlink_to(test_folder_path, target_is_directory=True) # So that it can be viewed from within the project working directory\n",
                "data_path = test_folder_path / \".repoyard\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6faf4c64",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Args (1/2)\n",
                "config_path = test_folder_path / \"repoyard_config\" / \"config.toml\"\n",
                "max_concurrent_rclone_ops = None\n",
                "repo_full_names = None\n",
                "storage_locations = None\n",
                "sync_direction = None\n",
                "verbose = True\n",
                "soft_interruption_enabled = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5fe4f6b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run init\n",
                "from repoyard.cmds import init_repoyard\n",
                "from repoyard.cmds import new_repo, sync_repo\n",
                "init_repoyard(config_path=config_path, data_path=data_path)\n",
                "\n",
                "# Add a storage location 'my_remote'\n",
                "import toml\n",
                "config_dump = toml.load(config_path)\n",
                "remote_rclone_path = Path(tempfile.mkdtemp(prefix=\"rclone_remote\", dir=\"/tmp\"))\n",
                "config_dump['storage_locations']['my_remote'] = {\n",
                "    'storage_type' : \"rclone\",\n",
                "    'store_path' : \"repoyard\",\n",
                "}\n",
                "config_path.write_text(toml.dumps(config_dump));"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "416caedf",
            "metadata": {},
            "source": [
                "# Function body"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb4b27f2",
            "metadata": {},
            "source": [
                "Process args"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ff22cc5",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export\n",
                "config = get_config(config_path)\n",
                "\n",
                "if repo_full_names is not None and storage_locations is not None:\n",
                "    raise ValueError(\"Cannot provide both `repo_full_names` and `storage_locations`.\")\n",
                "\n",
                "if max_concurrent_rclone_ops is None:\n",
                "    max_concurrent_rclone_ops = config.max_concurrent_rclone_ops\n",
                "    \n",
                "if soft_interruption_enabled:\n",
                "    enable_soft_interruption()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7fe85bd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up a rclone remote path for testing\n",
                "config.rclone_config_path.write_text(f\"\"\"\n",
                "[my_remote]\n",
                "type = alias\n",
                "remote = {remote_rclone_path}\n",
                "\"\"\");\n",
                "\n",
                "# Set up synced repos\n",
                "import asyncio\n",
                "async def _task(i):\n",
                "    repo_full_name = new_repo(config_path=config_path, repo_name=f\"test_repo{i}\", storage_location=\"my_remote\")\n",
                "    await sync_repo(config_path=config_path, repo_full_name=repo_full_name)\n",
                "await asyncio.gather(*[_task(i) for i in range(3)]);"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0ab8597c",
            "metadata": {},
            "source": [
                "Sync remote repometas that have not been synced locally already (i.e. 'undiscovered' repometas)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bfdf4108",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export\n",
                "if check_interrupted(): raise SoftInterruption()\n",
                "\n",
                "from repoyard._utils import rclone_lsjson, rclone_sync, async_throttler\n",
                "from repoyard._models import RepoMeta, SyncRecord, RepoPart, get_repoyard_meta\n",
                "\n",
                "for sl_name, sl_config in config.storage_locations.items():\n",
                "    if sl_config.storage_type == StorageType.LOCAL: continue\n",
                "\n",
                "    if storage_locations is not None and sl_name not in storage_locations:\n",
                "        continue\n",
                "    \n",
                "    # Get remote repometas\n",
                "    _ls_remote = await rclone_lsjson(\n",
                "        config.rclone_config_path,\n",
                "        source=sl_name,\n",
                "        source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,\n",
                "        files_only=True,\n",
                "        recursive=True,\n",
                "        filter=[f\"+ {const.REPO_METAFILE_REL_PATH}\"],\n",
                "        max_depth=2,\n",
                "    )\n",
                "    _ls_remote = {f[\"Path\"] for f in _ls_remote} if _ls_remote else set()\n",
                "\n",
                "    _ls_local = await rclone_lsjson(\n",
                "        config.rclone_config_path,\n",
                "        source=\"\",\n",
                "        source_path=config.local_store_path / sl_name,\n",
                "        files_only=True,\n",
                "        recursive=True,\n",
                "        filter=[f\"+ /{const.REPO_METAFILE_REL_PATH}\"],\n",
                "        max_depth=2,\n",
                "    )\n",
                "    _ls_local = {f[\"Path\"] for f in _ls_local} if _ls_local else set()\n",
                "\n",
                "    missing_metas = _ls_remote - _ls_local\n",
                "    missing_repo_full_names = [Path(p).parts[0] for p in missing_metas]\n",
                "\n",
                "    if repo_full_names is not None:\n",
                "        missing_metas = [missing_meta for repo_full_name, missing_meta in zip(missing_repo_full_names, missing_metas) if repo_full_name in repo_full_names]\n",
                "\n",
                "    if check_interrupted(): raise SoftInterruption()\n",
                "    \n",
                "    if len(missing_metas) > 0:\n",
                "        await rclone_sync(\n",
                "            rclone_config_path=config.rclone_config_path,\n",
                "            source=sl_name,\n",
                "            source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,\n",
                "            dest=\"\",\n",
                "            dest_path=config.local_store_path / sl_name,\n",
                "            filter=[f\"+ /{p}\" for p in missing_metas] + [\"- **\"],\n",
                "            exclude=[],\n",
                "        )\n",
                "\n",
                "        # Create sync records\n",
                "        async def _task(repo_full_name):\n",
                "            repo_meta = RepoMeta.load(config, sl_name, repo_full_name) # Used to get the paths consistently\n",
                "            rec = await SyncRecord.rclone_read(config.rclone_config_path, sl_name, repo_meta.get_remote_sync_record_path(config, RepoPart.META))\n",
                "            await rec.rclone_save(config.rclone_config_path, \"\", repo_meta.get_local_sync_record_path(config, RepoPart.META))\n",
                "        await async_throttler(\n",
                "            [_task(repo_full_name) for repo_full_name in missing_repo_full_names],\n",
                "            max_concurrency=max_concurrent_rclone_ops,\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc424d30",
            "metadata": {},
            "source": [
                "Sync the remaining repometas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "35626433",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modify a local repometa to test if it syncs properly\n",
                "repoyard_meta = get_repoyard_meta(config)\n",
                "repo_meta = list(repoyard_meta.by_full_name.values())[0]\n",
                "repo_meta.groups = [\"group1\", \"group2\"]\n",
                "repo_meta.save(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "81ad0cc8",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export\n",
                "from repoyard.cmds._sync_repo import RepoPart, sync_repo\n",
                "repoyard_meta = get_repoyard_meta(config)\n",
                "\n",
                "repo_meta_sync_res = []\n",
                "\n",
                "async def _task(repo_meta):\n",
                "    if check_interrupted(): raise SoftInterruption()\n",
                "    \n",
                "    if repo_full_names is not None and repo_meta.full_name not in repo_full_names: return\n",
                "    if storage_locations is not None and repo_meta.storage_location not in storage_locations: return\n",
                "\n",
                "    sync_res = None\n",
                "    try:\n",
                "        sync_res = await sync_repo(\n",
                "            config_path=config_path,\n",
                "            repo_full_name=repo_meta.full_name,\n",
                "            sync_direction=None,\n",
                "            sync_setting=SyncSetting.CAREFUL,\n",
                "            sync_choices=[RepoPart.META],\n",
                "            verbose=False,\n",
                "        )\n",
                "        sync_pre_status, sync_happened = sync_res[RepoPart.META]\n",
                "        repo_meta_sync_res.append((True, None, sync_pre_status, sync_happened))\n",
                "    except SyncFailed as e:\n",
                "        repo_meta_sync_res.append((False, e, sync_res, False))\n",
                "    except SyncUnsafe as e:\n",
                "        repo_meta_sync_res.append((False, e, sync_res, False))\n",
                "    except InvalidRemotePath as e:\n",
                "        repo_meta_sync_res.append((False, e, sync_res, False))\n",
                "\n",
                "await async_throttler(\n",
                "    [_task(repo_meta) for repo_meta in repoyard_meta.repo_metas],\n",
                "    max_concurrency=max_concurrent_rclone_ops,\n",
                ");"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e785cfae",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modify a local repometa to test if it syncs properly\n",
                "from repoyard._models import get_repoyard_meta, RepoMeta\n",
                "repoyard_meta = get_repoyard_meta(config)\n",
                "repo_meta = list(repoyard_meta.by_full_name.values())[0]\n",
                "import toml\n",
                "_groups = toml.loads((remote_rclone_path / \"repoyard\" / const.REMOTE_REPOS_REL_PATH / repo_meta.full_name / \"repometa.toml\").read_text())[\"groups\"]\n",
                "assert \"group1\" in _groups\n",
                "assert \"group2\" in _groups"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b867b676",
            "metadata": {},
            "source": [
                "Refresh the repoyard meta file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cdb919ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export\n",
                "from repoyard._models import refresh_repoyard_meta\n",
                "refresh_repoyard_meta(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94325dc2",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|func_return\n",
                "missing_metas, repo_meta_sync_res;"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "cell_metadata_filter": "-all",
            "main_language": "python",
            "notebook_metadata_filter": "-all"
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "nblite_source_hash": "f6c47b4db6a447481d81a6fb3107247652b3f06d2a0636e476fb9d19e145779c"
    },
    "nbformat": 4,
    "nbformat_minor": 5
}