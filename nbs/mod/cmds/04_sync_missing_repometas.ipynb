{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# _sync_missing_repometas",
      "metadata": {},
      "id": "cell0"
    },
    {
      "cell_type": "code",
      "source": "#|default_exp cmds._sync_missing_repometas\n#|export_as_func true",
      "metadata": {},
      "id": "cell1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|hide\nimport nblite; from nblite import show_doc; nblite.nbl_export()",
      "metadata": {},
      "id": "cell2",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|top_export\nfrom pathlib import Path\n\nfrom repoyard.config import get_config, StorageType\nfrom repoyard._utils.sync_helper import SyncFailed, SyncUnsafe, InvalidRemotePath, SyncStatus, SyncSetting, SyncDirection\nfrom repoyard._utils import check_interrupted, enable_soft_interruption, SoftInterruption\nfrom repoyard import const",
      "metadata": {},
      "id": "cell3",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|set_func_signature\nasync def sync_missing_repometas(\n    config_path: Path,\n    max_concurrent_rclone_ops: int|None = None,\n    repo_index_names: list[str]|None = None,\n    storage_locations: list[str]|None = None,\n    sync_setting: SyncSetting = SyncSetting.CAREFUL,\n    sync_direction: SyncDirection|None = None,\n    verbose: bool = False,\n    soft_interruption_enabled: bool = True,\n) -> tuple[list[str], list[tuple[bool, SyncFailed|SyncUnsafe|InvalidRemotePath|None, SyncStatus, bool]]]:\n    \"\"\"\n    \"\"\"\n    ...",
      "metadata": {},
      "id": "cell4",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Set up testing args",
      "metadata": {},
      "id": "cell5"
    },
    {
      "cell_type": "code",
      "source": "from tests.utils import *\nremote_name, remote_rclone_path, config, config_path, data_path = create_repoyards()",
      "metadata": {},
      "id": "cell6",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Args (1/2)\nconfig_path = config_path\nmax_concurrent_rclone_ops = None\nrepo_index_names = None\nstorage_locations = None\nsync_direction = None\nverbose = True\nsoft_interruption_enabled = True",
      "metadata": {},
      "id": "cell7",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Function body",
      "metadata": {},
      "id": "cell8"
    },
    {
      "cell_type": "markdown",
      "source": "Process args",
      "metadata": {},
      "id": "cell9"
    },
    {
      "cell_type": "code",
      "source": "#|export\nconfig = get_config(config_path)\n\nif repo_index_names is not None and storage_locations is not None:\n    raise ValueError(\"Cannot provide both `repo_index_names` and `storage_locations`.\")\n\nif max_concurrent_rclone_ops is None:\n    max_concurrent_rclone_ops = config.max_concurrent_rclone_ops\n    \nif soft_interruption_enabled:\n    enable_soft_interruption()",
      "metadata": {},
      "id": "cell10",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Set up synced repos\nfrom repoyard.cmds import new_repo, sync_repo\nimport asyncio\nasync def _task(i):\n    repo_index_name = new_repo(config_path=config_path, repo_name=f\"test_repo{i}\", storage_location=\"my_remote\")\n    await sync_repo(config_path=config_path, repo_index_name=repo_index_name)\nawait asyncio.gather(*[_task(i) for i in range(3)]);",
      "metadata": {},
      "id": "cell11",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sync remote repometas that have not been synced locally already (i.e. 'undiscovered' repometas)",
      "metadata": {},
      "id": "cell12"
    },
    {
      "cell_type": "code",
      "source": "#|export\nif check_interrupted(): raise SoftInterruption()\n\nfrom repoyard._utils import rclone_lsjson, rclone_sync, async_throttler\nfrom repoyard._models import RepoMeta, SyncRecord, RepoPart, get_repoyard_meta\n\nfor sl_name, sl_config in config.storage_locations.items():\n    if sl_config.storage_type == StorageType.LOCAL: continue\n\n    if storage_locations is not None and sl_name not in storage_locations:\n        continue\n    \n    # Get remote repometas\n    _ls_remote = await rclone_lsjson(\n        config.rclone_config_path,\n        source=sl_name,\n        source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,\n        files_only=True,\n        recursive=True,\n        filter=[f\"+ {const.REPO_METAFILE_REL_PATH}\"],\n        max_depth=2,\n    )\n    _ls_remote = {f[\"Path\"] for f in _ls_remote} if _ls_remote else set()\n    \n    _ls_local = await rclone_lsjson(\n        config.rclone_config_path,\n        source=\"\",\n        source_path=config.local_store_path / sl_name,\n        files_only=True,\n        recursive=True,\n        filter=[f\"+ /{const.REPO_METAFILE_REL_PATH}\"],\n        max_depth=2,\n    )\n    _ls_local = {f[\"Path\"] for f in _ls_local} if _ls_local else set()\n\n    missing_metas = _ls_remote - _ls_local\n    missing_repo_index_names = [Path(p).parts[0] for p in missing_metas]\n\n    if repo_index_names is not None:\n        missing_metas = [missing_meta for repo_index_name, missing_meta in zip(missing_repo_index_names, missing_metas) if repo_index_name in repo_index_names]\n\n    if check_interrupted(): raise SoftInterruption()\n    \n    if len(missing_metas) > 0:\n        if verbose:\n            print(f\"Syncing {len(missing_metas)} missing repometas from '{sl_name}'.\")\n            for missing_meta in missing_metas:\n                print(f\"  - {missing_meta}\")\n\n        await rclone_sync(\n            rclone_config_path=config.rclone_config_path,\n            source=sl_name,\n            source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,\n            dest=\"\",\n            dest_path=config.local_store_path / sl_name,\n            filter=[f\"+ /{p}\" for p in missing_metas] + [\"- **\"],\n            exclude=[],\n        )\n\n        # Create sync records\n        async def _task(repo_index_name):\n            repo_meta = RepoMeta.load(config, sl_name, repo_index_name) # Used to get the paths consistently\n            rec = await SyncRecord.rclone_read(config.rclone_config_path, sl_name, repo_meta.get_remote_sync_record_path(config, RepoPart.META))\n            await rec.rclone_save(config.rclone_config_path, \"\", repo_meta.get_local_sync_record_path(config, RepoPart.META))\n        await async_throttler(\n            [_task(repo_index_name) for repo_index_name in missing_repo_index_names],\n            max_concurrency=max_concurrent_rclone_ops,\n        )\n    else:\n        if verbose:\n            print(f\"No missing repometas in '{sl_name}' to sync.\")",
      "metadata": {},
      "id": "cell13",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing repometas in 'my_remote' to sync.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Refresh the repoyard meta file",
      "metadata": {},
      "id": "cell14"
    },
    {
      "cell_type": "code",
      "source": "#|export\nfrom repoyard._models import refresh_repoyard_meta\nrefresh_repoyard_meta(config)",
      "metadata": {},
      "id": "cell15",
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": "RepoyardMeta(repo_metas=[RepoMeta(creation_timestamp_utc='20260122', repo_subid='dfcl0', name='test_repo2', storage_location='my_remote', creator_hostname='Lukas\u2019s MacBook Pro', groups=[]), RepoMeta(creation_timestamp_utc='20260122', repo_subid='mo64t', name='test_repo0', storage_location='my_remote', creator_hostname='Lukas\u2019s MacBook Pro', groups=[]), RepoMeta(creation_timestamp_utc='20260122', repo_subid='oierb', name='test_repo1', storage_location='my_remote', creator_hostname='Lukas\u2019s MacBook Pro', groups=[])])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#|func_return\nmissing_metas;",
      "metadata": {},
      "id": "cell16",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "nblite_source_hash": "b3df1f42b5de264764d9bc077941867b6660a6a31197e4bef3dffb50263270c0"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
