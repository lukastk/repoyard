{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "245c0f01",
            "metadata": {},
            "source": [
                "# _sync_missing_repometas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d606b70",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|default_exp cmds._sync_missing_repometas\n",
                "#|export_as_func true"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bfaacde3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Environment variable DISABLE_NBLITE_EXPORT is set to True, skipping export.\n"
                    ]
                }
            ],
            "source": [
                "#|hide\n",
                "import nblite; from nblite import show_doc; nblite.nbl_export()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6943373e",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|top_export\n",
                "from pathlib import Path\n",
                "\n",
                "from repoyard.config import get_config, StorageType\n",
                "from repoyard._utils.sync_helper import SyncFailed, SyncUnsafe, InvalidRemotePath, SyncStatus, SyncSetting, SyncDirection\n",
                "from repoyard._utils import check_interrupted, enable_soft_interruption, SoftInterruption\n",
                "from repoyard import const"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5dff643",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|set_func_signature\n",
                "async def sync_missing_repometas(\n",
                "    config_path: Path,\n",
                "    max_concurrent_rclone_ops: int|None = None,\n",
                "    repo_full_names: list[str]|None = None,\n",
                "    storage_locations: list[str]|None = None,\n",
                "    sync_setting: SyncSetting = SyncSetting.CAREFUL,\n",
                "    sync_direction: SyncDirection|None = None,\n",
                "    verbose: bool = False,\n",
                "    soft_interruption_enabled: bool = True,\n",
                ") -> tuple[list[str], list[tuple[bool, SyncFailed|SyncUnsafe|InvalidRemotePath|None, SyncStatus, bool]]]:\n",
                "    \"\"\"\n",
                "    \"\"\"\n",
                "    ..."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "442d6588",
            "metadata": {},
            "source": [
                "Set up testing args"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fedcf7f0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tests.utils import *\n",
                "remote_name, remote_rclone_path, config, config_path, data_path = create_repoyards()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6faf4c64",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Args (1/2)\n",
                "config_path = config_path\n",
                "max_concurrent_rclone_ops = None\n",
                "repo_full_names = None\n",
                "storage_locations = None\n",
                "sync_direction = None\n",
                "verbose = True\n",
                "soft_interruption_enabled = True"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "416caedf",
            "metadata": {},
            "source": [
                "# Function body"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb4b27f2",
            "metadata": {},
            "source": [
                "Process args"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ff22cc5",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export\n",
                "config = get_config(config_path)\n",
                "\n",
                "if repo_full_names is not None and storage_locations is not None:\n",
                "    raise ValueError(\"Cannot provide both `repo_full_names` and `storage_locations`.\")\n",
                "\n",
                "if max_concurrent_rclone_ops is None:\n",
                "    max_concurrent_rclone_ops = config.max_concurrent_rclone_ops\n",
                "    \n",
                "if soft_interruption_enabled:\n",
                "    enable_soft_interruption()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7fe85bd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up synced repos\n",
                "from repoyard.cmds import new_repo, sync_repo\n",
                "import asyncio\n",
                "async def _task(i):\n",
                "    repo_full_name = new_repo(config_path=config_path, repo_name=f\"test_repo{i}\", storage_location=\"my_remote\")\n",
                "    await sync_repo(config_path=config_path, repo_full_name=repo_full_name)\n",
                "await asyncio.gather(*[_task(i) for i in range(3)]);"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0ab8597c",
            "metadata": {},
            "source": [
                "Sync remote repometas that have not been synced locally already (i.e. 'undiscovered' repometas)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bfdf4108",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "No missing repometas in 'my_remote' to sync.\n"
                    ]
                }
            ],
            "source": [
                "#|export\n",
                "if check_interrupted(): raise SoftInterruption()\n",
                "\n",
                "from repoyard._utils import rclone_lsjson, rclone_sync, async_throttler\n",
                "from repoyard._models import RepoMeta, SyncRecord, RepoPart, get_repoyard_meta\n",
                "\n",
                "for sl_name, sl_config in config.storage_locations.items():\n",
                "    if sl_config.storage_type == StorageType.LOCAL: continue\n",
                "\n",
                "    if storage_locations is not None and sl_name not in storage_locations:\n",
                "        continue\n",
                "    \n",
                "    # Get remote repometas\n",
                "    _ls_remote = await rclone_lsjson(\n",
                "        config.rclone_config_path,\n",
                "        source=sl_name,\n",
                "        source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,\n",
                "        files_only=True,\n",
                "        recursive=True,\n",
                "        filter=[f\"+ {const.REPO_METAFILE_REL_PATH}\"],\n",
                "        max_depth=2,\n",
                "    )\n",
                "    _ls_remote = {f[\"Path\"] for f in _ls_remote} if _ls_remote else set()\n",
                "    \n",
                "    _ls_local = await rclone_lsjson(\n",
                "        config.rclone_config_path,\n",
                "        source=\"\",\n",
                "        source_path=config.local_store_path / sl_name,\n",
                "        files_only=True,\n",
                "        recursive=True,\n",
                "        filter=[f\"+ /{const.REPO_METAFILE_REL_PATH}\"],\n",
                "        max_depth=2,\n",
                "    )\n",
                "    _ls_local = {f[\"Path\"] for f in _ls_local} if _ls_local else set()\n",
                "\n",
                "    missing_metas = _ls_remote - _ls_local\n",
                "    missing_repo_full_names = [Path(p).parts[0] for p in missing_metas]\n",
                "\n",
                "    if repo_full_names is not None:\n",
                "        missing_metas = [missing_meta for repo_full_name, missing_meta in zip(missing_repo_full_names, missing_metas) if repo_full_name in repo_full_names]\n",
                "\n",
                "    if check_interrupted(): raise SoftInterruption()\n",
                "    \n",
                "    if len(missing_metas) > 0:\n",
                "        if verbose:\n",
                "            print(f\"Syncing {len(missing_metas)} missing repometas from '{sl_name}'.\")\n",
                "            for missing_meta in missing_metas:\n",
                "                print(f\"  - {missing_meta}\")\n",
                "\n",
                "        await rclone_sync(\n",
                "            rclone_config_path=config.rclone_config_path,\n",
                "            source=sl_name,\n",
                "            source_path=sl_config.store_path / const.REMOTE_REPOS_REL_PATH,\n",
                "            dest=\"\",\n",
                "            dest_path=config.local_store_path / sl_name,\n",
                "            filter=[f\"+ /{p}\" for p in missing_metas] + [\"- **\"],\n",
                "            exclude=[],\n",
                "        )\n",
                "\n",
                "        # Create sync records\n",
                "        async def _task(repo_full_name):\n",
                "            repo_meta = RepoMeta.load(config, sl_name, repo_full_name) # Used to get the paths consistently\n",
                "            rec = await SyncRecord.rclone_read(config.rclone_config_path, sl_name, repo_meta.get_remote_sync_record_path(config, RepoPart.META))\n",
                "            await rec.rclone_save(config.rclone_config_path, \"\", repo_meta.get_local_sync_record_path(config, RepoPart.META))\n",
                "        await async_throttler(\n",
                "            [_task(repo_full_name) for repo_full_name in missing_repo_full_names],\n",
                "            max_concurrency=max_concurrent_rclone_ops,\n",
                "        )\n",
                "    else:\n",
                "        if verbose:\n",
                "            print(f\"No missing repometas in '{sl_name}' to sync.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b867b676",
            "metadata": {},
            "source": [
                "Refresh the repoyard meta file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cdb919ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|export\n",
                "from repoyard._models import refresh_repoyard_meta\n",
                "refresh_repoyard_meta(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94325dc2",
            "metadata": {},
            "outputs": [],
            "source": [
                "#|func_return\n",
                "missing_metas;"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "cell_metadata_filter": "-all",
            "main_language": "python",
            "notebook_metadata_filter": "-all"
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "nblite_source_hash": "5e9c8ae439b193d2edcc00dbb43accb2bc6004605d256a79b66ea52ea3cb6526"
    },
    "nbformat": 4,
    "nbformat_minor": 5
}